{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import os\n",
    "from skimage.transform import resize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPool2D, Dense, Flatten, Dropout\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/silvana/Documents/Projects/TrafficSigns'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cwd = os.getcwd()\n",
    "cwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=RGB size=71x72 at 0x7F8ABD253430>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = Image.open('82373-191501-bundle-archive/Train/1/00001_00000_00016.png')\n",
    "img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data is organized in train, test, and meta folders. The train folder contains 43 subfolders (corresponding to the 43 different classes), each containing images from the respective class. The test folder contains images that need to be classified. In the meta folder we find sign images. \n",
    "\n",
    "First step is to combine the images in the training dataset in two lists -- one containing the image name and the other one containing its label. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "labels = []\n",
    "\n",
    "for i in range(43):\n",
    "    class_path = cwd + '/82373-191501-bundle-archive/Train/' + str(i)\n",
    "    class_folder = os.listdir(class_path)\n",
    "    \n",
    "    for img in class_folder:\n",
    "        img = Image.open(class_path + '/' + img)\n",
    "        img = np.array(img)\n",
    "        images.append(img)\n",
    "        labels.append(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most powerful models for handling image data are CNNs. Before feeding the images into such a model, we want to make sure they are of the same size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_width = 10**6\n",
    "max_width = 0\n",
    "min_height = 10**6\n",
    "max_height = 0;\n",
    "channels = 10\n",
    "\n",
    "for i in range(len(images)):\n",
    "    if images[i].shape[0]  < min_width: \n",
    "        min_width = images[i].shape[0]\n",
    "    if images[i].shape[0]  > max_width: \n",
    "        max_width = images[i].shape[0]\n",
    "    if images[i].shape[1]  < min_height: \n",
    "        min_height = images[i].shape[1]\n",
    "    if images[i].shape[1]  > max_height: \n",
    "        max_height = images[i].shape[1]\n",
    "    if images[i].shape[2]  < channels: \n",
    "        channels = images[i].shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min/max width: 25 225\n",
      "min/max height: 25 243\n",
      "min number of channels: 3\n"
     ]
    }
   ],
   "source": [
    "print('min/max width:', min_width, max_width)\n",
    "print('min/max height:', min_height, max_height)\n",
    "print('min number of channels:', channels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since both *min_width* and *min_height* are 25, we are going to resize all images to be of shape 25x25 pixels. All images in the data size have 3 channels, i.e. are colorful images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_resized = []\n",
    "\n",
    "for i in range(len(images)):\n",
    "    images_resized.append(resize(images[i], (25, 25)))\n",
    "    \n",
    "images_resized = np.array(images_resized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39209, 25, 25, 3) (39209,)\n"
     ]
    }
   ],
   "source": [
    "# converto to numpy arrays\n",
    "images_resized = np.array(images_resized)\n",
    "labels = np.array(labels)\n",
    "\n",
    "print(images_resized.shape, labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the classes into a categorical variable\n",
    "labels = to_categorical(labels, 43)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train and test datasets\n",
    "images_train, images_valid, labels_train, labels_valid = train_test_split(images_resized, labels, \n",
    "                                                                        test_size=0.2, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the model\n",
    "input_shape = images_train[0].shape\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(128, kernel_size=(3,3), activation='relu', input_shape=input_shape))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Conv2D(64, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(43, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31367, 25, 25, 3) (31367, 43)\n",
      "(7842, 25, 25, 3) (7842, 43)\n"
     ]
    }
   ],
   "source": [
    "print(images_train.shape, labels_train.shape)\n",
    "print(images_valid.shape, labels_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "491/491 [==============================] - 34s 70ms/step - loss: 1.5083 - accuracy: 0.5988 - val_loss: 0.4971 - val_accuracy: 0.8704\n",
      "Epoch 2/50\n",
      "491/491 [==============================] - 46s 94ms/step - loss: 0.3058 - accuracy: 0.9228 - val_loss: 0.2237 - val_accuracy: 0.9472\n",
      "Epoch 3/50\n",
      "491/491 [==============================] - 51s 104ms/step - loss: 0.1626 - accuracy: 0.9603 - val_loss: 0.1852 - val_accuracy: 0.9522\n",
      "Epoch 4/50\n",
      "491/491 [==============================] - 53s 108ms/step - loss: 0.1056 - accuracy: 0.9745 - val_loss: 0.1258 - val_accuracy: 0.9742\n",
      "Epoch 5/50\n",
      "491/491 [==============================] - 50s 102ms/step - loss: 0.0771 - accuracy: 0.9813 - val_loss: 0.1107 - val_accuracy: 0.9768\n",
      "Epoch 6/50\n",
      "491/491 [==============================] - 49s 100ms/step - loss: 0.0585 - accuracy: 0.9861 - val_loss: 0.1047 - val_accuracy: 0.9778\n",
      "Epoch 7/50\n",
      "491/491 [==============================] - 48s 97ms/step - loss: 0.0454 - accuracy: 0.9885 - val_loss: 0.1214 - val_accuracy: 0.9728\n",
      "Epoch 8/50\n",
      "491/491 [==============================] - 47s 96ms/step - loss: 0.0367 - accuracy: 0.9908 - val_loss: 0.1063 - val_accuracy: 0.9758\n",
      "Epoch 9/50\n",
      "491/491 [==============================] - 45s 92ms/step - loss: 0.0325 - accuracy: 0.9921 - val_loss: 0.0987 - val_accuracy: 0.9815\n",
      "Epoch 10/50\n",
      "491/491 [==============================] - 42s 86ms/step - loss: 0.0303 - accuracy: 0.9926 - val_loss: 0.0884 - val_accuracy: 0.9827\n",
      "Epoch 11/50\n",
      "491/491 [==============================] - 38s 78ms/step - loss: 0.0184 - accuracy: 0.9955 - val_loss: 0.0896 - val_accuracy: 0.9856\n",
      "Epoch 12/50\n",
      "491/491 [==============================] - 45s 92ms/step - loss: 0.0193 - accuracy: 0.9952 - val_loss: 0.0900 - val_accuracy: 0.9837\n",
      "Epoch 13/50\n",
      "491/491 [==============================] - 46s 94ms/step - loss: 0.0206 - accuracy: 0.9945 - val_loss: 0.0980 - val_accuracy: 0.9830\n",
      "Epoch 14/50\n",
      "491/491 [==============================] - 42s 85ms/step - loss: 0.0249 - accuracy: 0.9938 - val_loss: 0.1253 - val_accuracy: 0.9742\n",
      "Epoch 15/50\n",
      "491/491 [==============================] - 40s 82ms/step - loss: 0.0165 - accuracy: 0.9957 - val_loss: 0.0807 - val_accuracy: 0.9869\n",
      "Epoch 16/50\n",
      "491/491 [==============================] - 41s 84ms/step - loss: 0.0103 - accuracy: 0.9974 - val_loss: 0.0942 - val_accuracy: 0.9839\n",
      "Epoch 17/50\n",
      "491/491 [==============================] - 43s 87ms/step - loss: 0.0169 - accuracy: 0.9958 - val_loss: 0.0941 - val_accuracy: 0.9832\n",
      "Epoch 18/50\n",
      "491/491 [==============================] - 43s 87ms/step - loss: 0.0084 - accuracy: 0.9980 - val_loss: 0.0786 - val_accuracy: 0.9874\n",
      "Epoch 19/50\n",
      "491/491 [==============================] - 41s 83ms/step - loss: 0.0044 - accuracy: 0.9993 - val_loss: 0.0846 - val_accuracy: 0.9856\n",
      "Epoch 20/50\n",
      "491/491 [==============================] - 40s 82ms/step - loss: 0.0154 - accuracy: 0.9955 - val_loss: 0.0867 - val_accuracy: 0.9860\n",
      "Epoch 21/50\n",
      "491/491 [==============================] - 41s 83ms/step - loss: 0.0118 - accuracy: 0.9972 - val_loss: 0.0809 - val_accuracy: 0.9875\n",
      "Epoch 22/50\n",
      "491/491 [==============================] - 39s 80ms/step - loss: 0.0053 - accuracy: 0.9990 - val_loss: 0.0754 - val_accuracy: 0.9901\n",
      "Epoch 23/50\n",
      "491/491 [==============================] - 44s 89ms/step - loss: 0.0021 - accuracy: 0.9999 - val_loss: 0.0722 - val_accuracy: 0.9901\n",
      "Epoch 24/50\n",
      "491/491 [==============================] - 40s 81ms/step - loss: 0.0013 - accuracy: 0.9999 - val_loss: 0.0729 - val_accuracy: 0.9902\n",
      "Epoch 25/50\n",
      "491/491 [==============================] - 40s 82ms/step - loss: 0.0204 - accuracy: 0.9947 - val_loss: 0.0886 - val_accuracy: 0.9842\n",
      "Epoch 26/50\n",
      "491/491 [==============================] - 37s 76ms/step - loss: 0.0117 - accuracy: 0.9969 - val_loss: 0.0907 - val_accuracy: 0.9861\n",
      "Epoch 27/50\n",
      "491/491 [==============================] - 36s 74ms/step - loss: 0.0049 - accuracy: 0.9987 - val_loss: 0.0688 - val_accuracy: 0.9909\n",
      "Epoch 28/50\n",
      "491/491 [==============================] - 36s 73ms/step - loss: 0.0062 - accuracy: 0.9983 - val_loss: 0.0885 - val_accuracy: 0.9853\n",
      "Epoch 29/50\n",
      "491/491 [==============================] - 36s 73ms/step - loss: 0.0051 - accuracy: 0.9986 - val_loss: 0.0672 - val_accuracy: 0.9903\n",
      "Epoch 30/50\n",
      "491/491 [==============================] - 36s 73ms/step - loss: 0.0019 - accuracy: 0.9997 - val_loss: 0.0708 - val_accuracy: 0.9916\n",
      "Epoch 31/50\n",
      "491/491 [==============================] - 36s 73ms/step - loss: 7.2391e-04 - accuracy: 1.0000 - val_loss: 0.0679 - val_accuracy: 0.9920\n",
      "Epoch 32/50\n",
      "491/491 [==============================] - 36s 73ms/step - loss: 4.3955e-04 - accuracy: 1.0000 - val_loss: 0.0696 - val_accuracy: 0.9916\n",
      "Epoch 33/50\n",
      "491/491 [==============================] - 65s 133ms/step - loss: 3.2646e-04 - accuracy: 1.0000 - val_loss: 0.0704 - val_accuracy: 0.9915\n",
      "Epoch 34/50\n",
      "491/491 [==============================] - 864s 2s/step - loss: 2.9518e-04 - accuracy: 1.0000 - val_loss: 0.0745 - val_accuracy: 0.9909\n",
      "Epoch 35/50\n",
      "491/491 [==============================] - 271s 552ms/step - loss: 2.2698e-04 - accuracy: 1.0000 - val_loss: 0.0734 - val_accuracy: 0.9920\n",
      "Epoch 36/50\n",
      "491/491 [==============================] - 751s 2s/step - loss: 0.0131 - accuracy: 0.9966 - val_loss: 0.1169 - val_accuracy: 0.9811\n",
      "Epoch 37/50\n",
      "491/491 [==============================] - 130s 265ms/step - loss: 0.0223 - accuracy: 0.9939 - val_loss: 0.0718 - val_accuracy: 0.9889\n",
      "Epoch 38/50\n",
      "491/491 [==============================] - 36s 73ms/step - loss: 0.0026 - accuracy: 0.9993 - val_loss: 0.0769 - val_accuracy: 0.9889\n",
      "Epoch 39/50\n",
      "491/491 [==============================] - 40s 81ms/step - loss: 0.0025 - accuracy: 0.9993 - val_loss: 0.0787 - val_accuracy: 0.9889\n",
      "Epoch 40/50\n",
      "491/491 [==============================] - 38s 77ms/step - loss: 0.0044 - accuracy: 0.9989 - val_loss: 0.0817 - val_accuracy: 0.9897\n",
      "Epoch 41/50\n",
      "491/491 [==============================] - 46s 94ms/step - loss: 0.0106 - accuracy: 0.9974 - val_loss: 0.0783 - val_accuracy: 0.9899\n",
      "Epoch 42/50\n",
      "491/491 [==============================] - 48s 98ms/step - loss: 0.0021 - accuracy: 0.9996 - val_loss: 0.0773 - val_accuracy: 0.9901\n",
      "Epoch 43/50\n",
      "491/491 [==============================] - 41s 83ms/step - loss: 9.1038e-04 - accuracy: 0.9998 - val_loss: 0.0752 - val_accuracy: 0.9912\n",
      "Epoch 44/50\n",
      "491/491 [==============================] - 39s 80ms/step - loss: 3.9850e-04 - accuracy: 1.0000 - val_loss: 0.0773 - val_accuracy: 0.9902\n",
      "Epoch 45/50\n",
      "491/491 [==============================] - 38s 77ms/step - loss: 0.0071 - accuracy: 0.9986 - val_loss: 0.0964 - val_accuracy: 0.9867\n",
      "Epoch 46/50\n",
      "491/491 [==============================] - 37s 76ms/step - loss: 0.0053 - accuracy: 0.9985 - val_loss: 0.1133 - val_accuracy: 0.9852\n",
      "Epoch 47/50\n",
      "491/491 [==============================] - 37s 75ms/step - loss: 0.0096 - accuracy: 0.9973 - val_loss: 0.1207 - val_accuracy: 0.9858\n",
      "Epoch 48/50\n",
      "491/491 [==============================] - 36s 74ms/step - loss: 0.0038 - accuracy: 0.9992 - val_loss: 0.1014 - val_accuracy: 0.9875\n",
      "Epoch 49/50\n",
      "491/491 [==============================] - 35s 70ms/step - loss: 3.8236e-04 - accuracy: 1.0000 - val_loss: 0.0831 - val_accuracy: 0.9917\n",
      "Epoch 50/50\n",
      "491/491 [==============================] - 35s 71ms/step - loss: 1.6424e-04 - accuracy: 1.0000 - val_loss: 0.0832 - val_accuracy: 0.9921\n"
     ]
    }
   ],
   "source": [
    "# train and validate the model\n",
    "history = model.fit(images_train, labels_train, batch_size=64, epochs=50, validation_data=(images_valid, labels_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# plot loss\n",
    "plt.figure()\n",
    "plt.plot(history.history['loss'], label='training')\n",
    "plt.plot(history.history['val_loss'], label='validation')\n",
    "plt.title('Loss')\n",
    "plt.legend()\n",
    "\n",
    "#plot accuracy\n",
    "plt.figure()\n",
    "plt.plot(history.history['accuracy'], label='training')\n",
    "plt.plot(history.history['val_accuracy'], label='validation')\n",
    "plt.title('Accuracy')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the model with unseen data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Width</th>\n",
       "      <th>Height</th>\n",
       "      <th>Roi.X1</th>\n",
       "      <th>Roi.Y1</th>\n",
       "      <th>Roi.X2</th>\n",
       "      <th>Roi.Y2</th>\n",
       "      <th>ClassId</th>\n",
       "      <th>Path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>53</td>\n",
       "      <td>54</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>48</td>\n",
       "      <td>49</td>\n",
       "      <td>16</td>\n",
       "      <td>Test/00000.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>42</td>\n",
       "      <td>45</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>36</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>Test/00001.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>48</td>\n",
       "      <td>52</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>43</td>\n",
       "      <td>47</td>\n",
       "      <td>38</td>\n",
       "      <td>Test/00002.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27</td>\n",
       "      <td>29</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>22</td>\n",
       "      <td>24</td>\n",
       "      <td>33</td>\n",
       "      <td>Test/00003.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>57</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>55</td>\n",
       "      <td>52</td>\n",
       "      <td>11</td>\n",
       "      <td>Test/00004.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Width  Height  Roi.X1  Roi.Y1  Roi.X2  Roi.Y2  ClassId            Path\n",
       "0     53      54       6       5      48      49       16  Test/00000.png\n",
       "1     42      45       5       5      36      40        1  Test/00001.png\n",
       "2     48      52       6       6      43      47       38  Test/00002.png\n",
       "3     27      29       5       5      22      24       33  Test/00003.png\n",
       "4     60      57       5       5      55      52       11  Test/00004.png"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test = pd.read_csv('82373-191501-bundle-archive/Test.csv')\n",
    "data_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img_files = data_test['Path']\n",
    "labels_test = data_test['ClassId']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in and resize the images\n",
    "images = []\n",
    "\n",
    "for img in test_img_files:\n",
    "    img = Image.open(cwd + '/82373-191501-bundle-archive/' + img)\n",
    "    img = img.resize((25,25))\n",
    "    img = np.array(img)\n",
    "    images.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_test = np.array(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict on the test dataset\n",
    "pred_labels = model.predict_classes(images_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9364212193190815"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(labels_test, pred_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('TraficSigns.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python37",
   "language": "python",
   "name": "python37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
